---
source: src/tokenizer.rs
expression: "contents.lines().filter_map(|line|\n                if line != \"\" {\n                        Some(format!(\"{line}\\n{:#?}\", Tokens :: from_str(line)))\n                    } else { None }).collect::<Vec<String>>().join(\"\\n\\n\")"
---
(lambda (x y) (+ x y))
Ok(
    Tokens(
        [
            ParenOpen,
            Keyword(
                Lambda,
            ),
            ParenOpen,
            Identifier(
                "x",
            ),
            Identifier(
                "y",
            ),
            ParenClose,
            ParenOpen,
            Identifier(
                "+",
            ),
            Identifier(
                "x",
            ),
            Identifier(
                "y",
            ),
            ParenClose,
            ParenClose,
        ],
    ),
)

(lambda (x y z) (= x y (= x z)))
Ok(
    Tokens(
        [
            ParenOpen,
            Keyword(
                Lambda,
            ),
            ParenOpen,
            Identifier(
                "x",
            ),
            Identifier(
                "y",
            ),
            Identifier(
                "z",
            ),
            ParenClose,
            ParenOpen,
            Identifier(
                "=",
            ),
            Identifier(
                "x",
            ),
            Identifier(
                "y",
            ),
            ParenOpen,
            Identifier(
                "=",
            ),
            Identifier(
                "x",
            ),
            Identifier(
                "z",
            ),
            ParenClose,
            ParenClose,
            ParenClose,
        ],
    ),
)
